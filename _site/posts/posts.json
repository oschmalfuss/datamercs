[
  {
    "path": "posts/welcome/",
    "title": "Welcome to OS DataMercs",
    "description": "OS DataMercs is inspired to elevate the publishing industry by consulting, encouraging and providing most recognized metadata services",
    "author": [
      {
        "name": "Olaf Schmalfuß",
        "url": "https://www.datamercs.net"
      }
    ],
    "date": "2022-02-15",
    "categories": [],
    "contents": "\r\n// Trinity of Discovery\r\nThe “Trinity of Discovery” exhibits our holistic approach to metadata delivery and creation and sets the framework to a title’s, may it be eBook or journal, (meta) data needs.\r\nIt is also what most libraries would expect to receive from a publisher one way or another, either directly or through third party services or union catalogues:\r\nmeta data and discovery from the smallest chunk down to collection level, because\r\n\r\n»We are not going to buy any of your eBooks if users cannot discover them.«\r\n(an unnamed head of aqcuisition)\r\n\r\nMARC records, KBARTs, ONIX and JATS XML are key, especially to scientific publishing houses!\r\nNaturally, one could go beyond that, if we talked about linked data, which would even aim at the most atomic bits of data points, but since most publishers usually have hardly even the basics covered, the trinity shall serve as our North star here.\r\nThus, this site aims to showcase several tools and workflows around that, so that even the smallest publisher, or inclined librarian, can build upon that and implement their own (half-) automated data pipelines, from ERP to .MRC;-)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/welcome/trinity of discovery.jpg",
    "last_modified": "2022-02-15T23:23:20+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-15-z3950-for-dummies/",
    "title": "Z39.50 for Dummies",
    "description": "This (cleaning up the vaults) is a shameless re-post of a now no longer available blogpost by Wolfram Schneider from Index Data, originally posted in 5 parts 2009/08/27-2010/01/13, which tought me a lot about implementing Z39.50 and the YAZ toolkit. I even printed it out back in the day and it is still worth reading today!",
    "author": [
      {
        "name": "Wolfram Schneider",
        "url": "https://wolfram.schneider.org"
      },
      {
        "name": "Olaf Schmalfuß",
        "url": {}
      }
    ],
    "date": "2020-08-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n// Z39.50 for Dummies\r\n// Z39.50 for Dummies Series - Part 1\r\n// Z39.50 for Dummies Part 2\r\n// Z39.50 for Dummies Series - Part 3\r\n// Z39.50 for Dummies - Part 4\r\n// Z39.50 for Dummies - Part 5\r\n\r\n\r\n// Z39.50 for Dummies\r\nby Wolfram Schneider on 2009/08/27\r\n(http://www.indexdata.com/blog/2009/08/z3950-dummies)\r\nOne of the things Index Data is known for is the YAZ toolkit - an open source programmers’ toolkit supporting the development of Z39.50/SRW/SRU clients and servers. The first release was in 1995 and I’ve been using it for my own metasearch engine ZACK Gateway since 1998, long before I joined Index Data.\r\nZ39.50 is a client-server protocol for searching and retrieving information from remote computer databases. It is a mature low level protocol like HTTP and FTP. You don’t implement Z39.50 yourself, you use the YAZ utilities and the libraries and frameworks for in other languages (C++, PHP, Perl, etc.).\r\nThere are many people who thinks that Z39.50 is a dead standard, and hard to understand. That is not true. Z39.50 is still growing in use, stable and very fast. It is the only widely available protocol for metasearch.\r\nUsing Z39.50 is not harder than using FTP. I think that the overhead for learning Z39.50 is less than a half day for an experienced programmer. Every problem which you have later is not related to the Z39.50 protocol itself, it is related to underlying system behind the Z39.50 server. Keep in mind that Z39.50 is an API to access (bibliographic) databases. It does not define how the data is structured and indexed in the database.\r\n// Z39.50 for Dummies Series - Part 1\r\nI will now start a Z39.50 for Dummies series and show some example how to access a remote database.\r\nI’m using in the following demos the zoomsh program from the YAZ toolkit\r\nLet’s start with a simple question: does the Library of Congress have the book “library mashups”? (I strongly recommend you buy this book - I wrote chapter 19):\r\n$ zoomsh \"connect z3950.loc.gov:7090/voyager\" 'search \"library mashups\"' quit\r\n\r\nz3950.loc.gov:7090/voyager: 2 hits\r\nThat’s all! Only one line on the command line. A SRU or SOAP request would not be shorter.\r\nNow, retrieve the record:\r\n$ zoomsh \"connect z3950.loc.gov:7090/voyager\" 'search \"library mashups\"' \"show 0 1\" \"quit\"\r\n\r\nz3950.loc.gov:7090/voyager: 2 hits\r\n0 database=VOYAGER syntax=USmarc schema=unknown\r\n02438cam 22003018a 4500\r\n001 15804854\r\n005 20090710141909.0\r\n008 090706s2009 nju b 001 0 eng\r\n906 $a 7 $b cbc $c orignew $d 1 $e ecip $f 20 $g y-gencatlg\r\n925 0 $a acquire $b 2 shelf copies $x policy default\r\n955 $b rg11 2009-07-06 $i rg11 2009-07-06 $a rg11 2009-07-08 to Policy (CLED/SHED)\r\n $a td04 2009-07-09 to Dewey $w rd14 2009-07-10\r\n010 $a 2009025999\r\n020 $a 9781573873727\r\n040 $a DLC $c DLC\r\n050 00 $a Z674.75.W67 $b L52 2009\r\n082 00 $a 020.285/4678 $2 22\r\n245 00 $a Library mashups : $b exploring new ways to deliver library\r\ndata / $c edited by Nicole C. Engard.\r\n260 $a Medford, N.J. : $b Information Today, Inc., $c c2009.\r\n263 $a 0908\r\n300 $a p. cm.\r\n504 $a Includes bibliographical references and index.\r\n505 0 $a What is a mashup? / Darlene Fichter -- Behind the scenes : some technical details on mashups / Bonaria Biancu -- Making your data available to be mashed up / Ross Singer -- Mashing up with librarian knowledge / Thomas Brevik -- Information in context / Brian Herzog -- Mashing up the library website / Lichen Rancourt -- Piping out library data / Nicole C. Engard -- Mashups @ Libraries interact / Corey Wallis -- Library catalog mashup : using Blacklight to expose collections / Bess Sadler, Joseph Gilbert, and Matt Mitchell -- Breaking into the OPAC / Tim Spalding -- Mashing up open data with biblios.net Web services / Joshua Ferraro -- SOPAC 2.0 : the thrashable, mashable catalog / John Blyberg -- Mashups with the WorldCat Affiliate Services / Karen A. Coombs -- Flickr and digital image collections / Mark Dahl and Jeremy McWilliams -- Blip.tv and digital video collections in the library / Jason A. Clark -- Where's the nearest computer lab? : mapping up campus / Derik A. Badman -- The repository mashup map / Stuart Lewis -- The LibraryThing API and libraries / Robin Hastings -- ZACK bookmaps / Wolfram Schneider -- Federated database search mashup / Stephen Hedges, Laura Solomon, and Karl Jendretzky -- Electronic dissertation mashups using SRU / Michael C. Witt.\r\n650 0 $a Mashups (World Wide Web) $x Library applications.\r\n650 0 $a Libraries and the Internet.\r\n650 0 $a Library Web sites $x Design.\r\n650 0 $a Web site development.\r\n700 1 $a Engard, Nicole C., $d 1979-\r\n963 $a Amy Reeve; phone: 609-654-6266; email: areeve @ infotoday.com; bc: nellor @ infotoday.com\r\nThe default exchange format for bibliographic records in Z39.50 is MARC21. This is maybe not what you want to parse yourself.\r\nOk, now let’s download the record in XML format:\r\n$ zoomsh \"connect z3950.loc.gov:7090/voyager\" 'search \"library mashups\"' \"show 0 1 xml\" \"quit\"\r\n\r\nz3950.loc.gov:7090/voyager: 2 hits\r\n0 database=VOYAGER syntax=USmarc schema=unknown\r\n<record xmlns=\"http://www.loc.gov/MARC21/slim\">\r\n <leader>02438cam a22003018a 4500<\/leader>\r\n <controlfield tag=\"001\">15804854<\/controlfield>\r\n <controlfield tag=\"005\">20090710141909.0<\/controlfield>\r\n <controlfield tag=\"008\">090706s2009 nju b 001 0 eng <\/controlfield>\r\n <datafield tag=\"906\" ind1=\" \" ind2=\" \">\r\n <subfield code=\"a\">7<\/subfield>\r\n <subfield code=\"b\">cbc<\/subfield>\r\n <subfield code=\"c\">orignew<\/subfield>\r\n <subfield code=\"d\">1<\/subfield>\r\n <subfield code=\"e\">ecip<\/subfield>\r\n <subfield code=\"f\">20<\/subfield>\r\n <subfield code=\"g\">y-gencatlg<\/subfield>\r\n <\/datafield>\r\n\r\n[large XML output...]\r\n<\/record>\r\nYou can parse the XML output with your favorite tools, usually an XSLT style sheet.\r\nNext time I will show you how to run a meta search in one line.\r\n-Wolfram\r\nUPDATE: The latest release of YAZ, inspired by this blog post, supports client-side mapping of MARC to MARCXML, so you can dump XML records even from targets that do not support XML.\r\n// Z39.50 for Dummies Part 2\r\nby Wolfram Schneider on 2009/08/31\r\n(http://www.indexdata.com/blog/2009/08/z3950-dummies-part-2)\r\nIn the last blog post Z39.50 for Dummies I gave an introduction on how to use the zoomsh program to access the Z39.50 Server of the Library of Congress.\r\nToday I will show you how to run a simple metasearch on the command line. You want to know which library has the book with the ISBN 0-13-949876-1 (UNIX network programming / W. Richard Stevens)? You can run the zoomsh in a shell loop.\r\nPut the list of databases (zURL’s) line by line in the text file zurl.txt:\r\nz3950.loc.gov:7090/voyager\r\nmelvyl.cdlib.org:210/CDL90\r\nlibrary.ox.ac.uk:210/ADVANCE\r\nz3950.library.wisc.edu:210/madison\r\nand run a little loop in a shell script:\r\n$ for zurl in `cat zurl.txt`\r\ndo\r\n zoomsh \"connect $zurl\" \\\r\n \"search @attr 1=7 0-13-949876-1\" \"quit\"\r\ndone\r\n\r\n\r\nz3950.loc.gov:7090/voyager: 0 hits\r\nmelvyl.cdlib.org:210/CDL90: 1 hits\r\nlibrary.ox.ac.uk:210/ADVANCE: 1 hits\r\nz3950.library.wisc.edu:210/madison: 0 hits \r\nOf course it takes time to run one search request after another. How about a parallel search? Modern xargs(1) commands on BSD based Operating Systems (MacOS, FreeBSD) and the GNU xargs supports to run several processes at a time.\r\nThis example runs up to 2 search request at a time and is 2 times faster than the shell script above:\r\n$ xargs -n1 -P2 perl -e 'exec \"zoomsh\", \"connect $ARGV[0]\", \"search \\@attr 1=7 0-13-949876-1\", \"quit\"' &lt; zurl.txt\r\n\r\nmelvyl.cdlib.org:210/CDL90: 1 hits\r\nlibrary.ox.ac.uk:210/ADVANCE: 1 hits\r\nz3950.loc.gov:7090/voyager: 0 hits\r\nz3950.library.wisc.edu:210/madison: 0 hits\r\nYou see here that the order of responses is different, the fastest databases wins and displayed first.\r\nI think it is safe to run up to 20 searches in parallel on modern hardware. Note that there is a lot of process overhead here, for each request 2 processes will be executed. If a connection hangs you must wait until you hit the time out.\r\nThis was an example how easy it is to run your own metasearch on the command line. If you want setup a real metasearch for your organization I recommend to try out our metasearch middleware pazpar2, featuring merging, relevance ranking, record sorting, and faceted results. In a nutshell, pazpar2 is a web-oriented Z39.50 client. It will search a lot of targets in parallel and provide on-the-fly integration of the results. The interface is entirely webservice-based, and you can use it from any development environment. The pazpar2 home page is http://www.indexdata.com/pazpar2\r\n// Z39.50 for Dummies Series - Part 3\r\nby Wolfram Schneider on 2009/09/09\r\n(http://www.indexdata.com/blog/2009/09/z3950-dummies-series-part-3)\r\nThis is part 3 of the Z39.50 series for dummies. In the first part I explained what Z39.50 is and how to run a simple search. In the second part I showed how to run a simple meta search on the command line.\r\nI searched for the book: UNIX network programming / W. Richard Stevens, ISBN 0-13-949876-1 in four large libraries:\r\n$ for zurl in `cat zurl.txt`\r\ndo\r\n zoomsh \"connect $zurl\" \\\r\n \"search @attr 1=7 0-13-949876-1\" \"quit\"\r\ndone\r\n\r\nz3950.loc.gov:7090/voyager: 0 hits\r\nmelvyl.cdlib.org:210/CDL90: 1 hits\r\nlibrary.ox.ac.uk:210/ADVANCE: 1 hits\r\nz3950.library.wisc.edu:210/madison: 0 hits\r\nOnly 2 out of 4 libraries own this must-have book. Can this be true? Well, lets modify the ISBN and search without dashes (‘-’)\r\n$ for zurl in `cat zurl.txt`\r\ndo\r\n zoomsh \"connect $zurl\" \\\r\n \"search @attr 1=7 0139498761\" \"quit\"\r\ndone\r\n\r\nz3950.loc.gov:7090/voyager: 1 hits\r\nmelvyl.cdlib.org:210/CDL90: 1 hits\r\nlibrary.ox.ac.uk:210/ADVANCE: 1 hits\r\nz3950.library.wisc.edu:210/madison: 1 hits\r\nBingo - every library has a copy of UNIX network programming by W. Richard Stevens!\r\nZ39.50 defines the syntax to search in a database. It does not define the semantic of a search, how an ISBN is structured.\r\nIf you build a search engine on top of Z39.50 you need an additional layer to handle the semantic of a search for each database. (You need this layer too to add workaround for broken implementations)\r\nIn this example above we must remove the dashes in an ISBN search for the Library of Congress and University of Wisconsin-Madinson Libraries.\r\nAnother thing which you must be aware: libraries use for historical reasons different character sets: utf-8, iso8859-1, iso5426 and marc8. You must convert your search query to the right character set for each library, for searching and retrieving the records.\r\nIn this article I described the challenges to run a meta search on top of Z39.50. All these problems are due the underlying databases and not Z39.50 - you will have the same problems if you use a web based XML services such as SRU or a proprietary, vendor-based API. The truth is that running a metasearch is not a trivial task.\r\n// Z39.50 for Dummies - Part 4\r\nby Wolfram Schneider on 2009/10/12\r\n(http://www.indexdata.com/blog/2009/10/z3950-dummies-part-4)\r\nThis is part 4 of the series Z39.50 for dummies.\r\nLibraries store and exchange bibliographic data in MARC records. A MARC record is a MAchine-Readable Cataloging record. It was developed at the Library of Congress (LoC) beginning in the 1960s.\r\nA dump of the LoC catalog (and other libraries) is available at the Internet Archive in the collection marcrecords. The LoC catalog dump is split into 29 files, part01.dat to part29.dat. Each file is roughly 200MB large.\r\nThe great news is that the data from LoC is public domain (already paid by the US taxpayers, thank you!) and you can use the data for your own system.\r\nBefore you can import data, you must validate, convert, or fix the bibliographic data. I will show now how you can do this with the Index Data YAZ toolkit. The YAZ toolkit contains the program yaz-marcdump to dump MARC records.\r\nyaz-marcdump called without an option will print the records in line format:\r\n$ yaz-marcdump part01.dat | more\r\n\r\n00720cam  22002051  4500\r\n001    00000002\r\n003 DLC\r\n005 20040505165105.0\r\n008 800108s1899    ilu           000 0 eng\r\n010    $a    00000002\r\n035    $a (OCoLC)5853149\r\n040    $a DLC $c DSI $d DLC\r\n050 00 $a RX671 $b .A92\r\n100 1  $a Aurand, Samuel Herbert, $d 1854-\r\n245 10 $a Botanical materia medica and pharmacology; $b drugs considered from a botanical, pharmaceutical, physiological, therapeutical and toxicological standpoint. $c By S. H. Aurand.\r\n260    $a Chicago, $b P. H. Mallen Company, $c 1899.\r\n300    $a 406 p. $c 24 cm.\r\n500    $a Homeopathic formulae.\r\n650  0 $a Botany, Medical.\r\n650  0 $a Homeopathy $x Materia medica and therapeutics.\r\n[...]\r\nFirst converts the MARC21 records in MARC-8 encoding to MARC21 in UTF-8 encoding:\r\n$ yaz-marcdump -f marc-8 -t utf-8 -o marc \\\r\n       part01.dat > part.mrc\r\nFor MARC21, the leader offset 9 tells whether it is really MARC8 (almost always the case) or whether it’s UTF-8. A MARC21 must have position 9=‘a’ (value 97). For this reason, the option -l for yaz-marcdump may come in handy:\r\n$ yaz-marcdump -f marc-8 -t utf-8 -o marc \\\r\n       -l 9=97 part01.dat > part.mrc\r\nIf you prefer MARCXML instead MARC21 records you may convert the records:\r\n$ yaz-marcdump -o marcxml -f MARC-8 -t UTF-8 \\\r\n    part01.dat > part.marcxml\r\n\r\n<collection xmlns=\"http://www.loc.gov/MARC21/slim\">\r\n<record>\r\n  <leader>00720cam a22002051  4500<\/leader>\r\n  <controlfield tag=\"001\">   00000002 <\/controlfield>\r\n  <controlfield tag=\"003\">DLC<\/controlfield>\r\n  <controlfield tag=\"005\">20040505165105.0<\/controlfield>\r\n  <controlfield tag=\"008\">800108s1899    ilu           000 0 eng\r\n<\/controlfield>\r\n  <datafield tag=\"010\" ind1=\" \" ind2=\" \">\r\n    <subfield code=\"a\">   00000002 <\/subfield>\r\n  <\/datafield>\r\n  <datafield tag=\"035\" ind1=\" \" ind2=\" \">\r\n    <subfield code=\"a\">(OCoLC)5853149<\/subfield>\r\n  <\/datafield>\r\n[...]\r\nThe Library of Congress has over 7 million records. That’s huge data, total 5.6GB raw data. If you compress that data it is only 1.7GB.\r\nTo convert compressed data, run yaz-marcdump in a UNIX pipe:\r\n$ zcat part01.dat.gz | yaz-marcdump -f MARC-8 \\\r\n  -t UTF-8 -o marcxml /dev/stdin > part01.marcxml \r\nYou can search a marc dump with the UNIX grep tool:\r\n$ yaz-marcdump -f marc-8 -t utf-8 part01.dat | \\\r\n      grep Sausalito\r\n\r\n260    $a Sausalito, Calif. : $b University Science Books, $c 2000.\r\n260    $a Sausalito, Calif. : $b Math Solutions Publications, $c c2000.\r\n260    $a Sausalito, Calif. : $b Post-Apollo Press, $c c2000.\r\n260    $a Sausalito, Calif. : $b University Science Books, $c c2002.\r\n260    $a Sausalito, Calif. : $b Post-Apollo Press, $c c2000.\r\n260    $a Sausalito, CA : $b Toland Communications, $c c2000.\r\n260    $a Sausalito, CA : $b In Between Books, $c 2001.\r\n[...]\r\nThe yaz-marcdump tool supports the character sets UTF-8, MARC-8, ISO8859-1, ISO5426 and some other encodings. For more information, see the yaz-iconv manual pages.\r\nIn this article I showed how to validate, convert, or fix bibliographic data dumped in MARC format. Next time I will show some advanced examples how to analyze MARC records on modern standard PC hardware.\r\n// Z39.50 for Dummies - Part 5\r\nby Wolfram Schneider on 2010/01/13\r\n(http://www.indexdata.com/blog/2010/01/z3950-dummies-part-5)\r\nThis is part 5 of the series Z39.50 for dummies. In the 4th part I showed how to run convert MARC21 records to line format or XML.\r\nIn this article I will show you how to analyze MARC data on a modern PC hardware. PC are very fast now and incredibly cheap. You can rent a quad-core Intel machine with 8GB RAM and unlimited traffic for 40 Euro/month (+VAT) in a data center.\r\nIf the computer is fast enough, you don’t have to spend too much time on complex algorithms. You can use the raw power of your computer and do a brute force approach.\r\nIn the following example I will use the 7 million records from a dump of the Library of Congress (LoC) catalog. For details, please read the previous article Z39.50 for Dummies - Part 4.\r\n$ for i in *.dat; do\r\n    yaz-marcdump -f marc-8 -t utf-8 -o line\r\n  done > loc.txt\r\n\r\n$ du -hs loc.txt\r\n4.9G\r\nThe line dump of the LoC is 4.9GB large and fits into main memory - great!\r\n# count for the last name “Calaminus”\r\n$ egrep -c Calaminus loc.txt\r\n4 hits, the search took 4 seconds real time\r\n# count records with <span class=\"caps\">ISBN<\/span> number\r\n$ egrep -c ^020 loc.txt\r\n3999863\r\nThere are nearly 4 million ISBN numbers (out of 7 million records). The search took 11 seconds.\r\n# count <span class=\"caps\">URL<\/span>s\r\n$ egrep -c http:// loc.txt\r\n265540\r\nThere are 265,540 URLs in the LoC records.\r\n# check for subject headings for the city of \r\n# Sausalito, California using regular expression\r\n$ egrep -c ‘^[67][0-<span class=\"caps\">9[0<\/span>-9].*Sausalito’ loc.txt\r\n19\r\nThere are 19 subject headings for Sausalito\r\n# search with a typo in name (a => o)\r\n$ egrep Sausolito loc.txt\r\nNo hits due a typo in the name, try it with agrep, a grep program with approximate matching capabilities:\r\n$ agrep -c -1 Sausolito loc.txt\r\n282\r\n282 hits, the search took 8 seconds\r\nThe examples above are for software developers and experienced librarians. They are helpful for a quick check of your bibliographic records, for data mining, analyzing or to double-check if your indexer works correctly.\r\nIf you want setup a public system for end-users you need of course a real full text engine as our zebra software.\r\nRead the other articles of the series Z39.50 for Dummies: Part I, Part II, Part III, Part IV, Part V\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-16T01:19:55+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-07-07-wintaskschedulerforcygwin/",
    "title": "Win Task Scheduler for cygwin",
    "description": "HowTo run bash scripts via Cygwin as Scheduled Task (i.e. \"Aufgabenplanung\") in Windows",
    "author": [
      {
        "name": "Olaf Schmalfuß",
        "url": {}
      }
    ],
    "date": "2020-07-07",
    "categories": [],
    "contents": "\r\nHowTo run bash script via Cygwin as Scheduled Task (i.e. “Aufgabenplanung”) in Windows\r\nFor process automation it is not necessary to rely on Outlook reminders if you’re on Windows and cannot (or want not) run Cron as a service to schedule scripts or programs:\r\nWindows brings its native service called “Scheduled Tasks” (or “Aufgabenplanung” in the German version)\r\n// Open “Scheduled Tasks” App\r\nhit Windows Key + R to open command prompt, enter taskschd.msc, which works regardless of Win version/ language\r\nalternatively\r\nsearch APP for either “Scheduled Task” or “Aufgabenplanung”\r\nor locate the “EXE” in C:\\Windows\\System32\\taskschd.msc\r\n…\r\n\r\n// Set up a new Job\r\nRight-click on an empty space in the Tasks’ overview and select “new task” (i.e. “Einfache Aufgabe erstellen”).\r\nIn “Actions” (i.e. “Aktionen”) enter the path to cygwin in the “Program/script” field, e.g.C:\\cygwin64\\bin\\bash.exe\r\nIn the “Add arguments” box, enter “-l -c” and the full path to the bash command to run surrounded by quotes in UNIX notation, i.e. with forward slashes and as seen from within cygwin, and not simply the Windows path, e.g.-l -c \"/tmp/pdw_test/pull_chapter_report_from_jobscheduler.sh\"\r\n -l: Run as if logged on at a shell\r\n -c: Run this command\r\nIn the “Start in” field enterC:\\cygwin64\\bin\r\nAdd a description and give your task a meaningful name, so that when you come back to it in a year you know what it’s for and you’re done!\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-07-07-wintaskschedulerforcygwin/example.png",
    "last_modified": "2022-02-15T22:20:35+01:00",
    "input_file": {},
    "preview_width": 1258,
    "preview_height": 839
  },
  {
    "path": "posts/2018-04-05-rbbkultur-mediathek-downloader/",
    "title": "rbbKultur - Mediathek-Downloader",
    "description": "HowTo download \"Mediathek\" features for archival purposes",
    "author": [
      {
        "name": "Olaf Schmalfuß",
        "url": {}
      }
    ],
    "date": "2018-04-05",
    "categories": [],
    "contents": "\r\nrbbKultur - Mediathek-Downloader\r\n// Introduction\r\nFor archival or educational purposes it might be useful to know how to download content from public radio and TV broadcasters’ archives, i.e. “Mediathek”.\r\nThis only works, when the program is archived as a whole file in a convenient format like mp3 or mp4, and not in a chunked m3u streaming format. This we will see in step 4. below. So if we encounter m3u, we will use VLC instead to capture and convert the stream, see:link to VLC howto\r\n1. select Program\r\nrbbKultur - Mediathek\r\n\r\nhttps://www.kulturradio.de/zum_nachhoeren/\r\n\r\nchose date and program\r\n2. inspect element\r\ni.e. launch Developer Tools\r\nFireFox: CTRL+SHIFT+C\r\nChrome: CTRL+SHIFT+I\r\n\r\n3. Start Mediathek player\r\ni.e. start the podcast or video once we have the Developer Tools open, so that we can analyze the traffic under Network\r\n4. back in Developer Tools\r\nunder Network right click on the File (media/ mpeg)\r\nthen Copy URL or copy as cURL\r\n\r\n\r\n\r\n5. Download via bash script\r\nadjust script\r\n\r\nrbb_downloader()\r\n  {\r\n    if [ -z \"$1\" ]\r\n      then echo \"Dateiname fehlt\"\r\n    elif [ -z \"$2\" ]\r\n      then  \"Download URL fehlt\"\r\n    else\r\n      DWNDIR=/tmp/Downloads/AlteMusik\r\n      AMDOWN=$1\r\n      rbbmediapmdp=$2\r\n      curl $rbbmediapmdp -o $DWNDIR/\"$AMDOWN\"\r\n      ls -htl $DWNDIR\r\n  fi\r\n  }\r\n  \r\n# usage:\r\nrbb_downloader \"File_Name\" \"Download_URL\"\r\n\r\noptional: save in bashrc\r\n\r\nC:\\cygwin64\\home\\schmalfuss\\.bashrc\r\n\r\nrun\r\ne.g. \r\n\r\n\r\nrbb_downloader \"Alte Musik - 2020-07-08 - Heinrich Isaac - Lieder und Motetten.mp3\" \"https://rbbmediapmdp-a.akamaihd.net/content/74/da/74da3627-5312-4f34-b681-93c48f12202d/0a858af8-b788-430b-9f5a-b5c678701a18_53d97702-265a-4586-a6d8-c8c7ad9bac80.mp3\"\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2018-04-05-rbbkultur-mediathek-downloader/dwnfunction.png",
    "last_modified": "2022-02-15T23:05:01+01:00",
    "input_file": {},
    "preview_width": 520,
    "preview_height": 340
  },
  {
    "path": "posts/2013-07-21-a-rough-guide-to-cold-brew/",
    "title": "A rough guide to cold brew",
    "description": "While to the common librarian Cory Doctorow is merely known as champion for Open Access, the Creative Commons, the EFF etc., he is also a hell of a barrista, introducing many a young scholar - the author included - to the carnality of cold brew.  \nSo, here is the rough guide for future reference.",
    "author": [
      {
        "name": "Olaf Schmalfuß",
        "url": "https://www.datamercs.net"
      }
    ],
    "date": "2013-07-21",
    "categories": [],
    "contents": "\r\n// essential reading\r\nHOWTO attain radical hotel-room coffee independence\r\neasier\r\nCheap, easy, no-mess cold-brew coffee\r\nbut frankly: simply use your French Press and let the coarse ground coffee brew over night in your fridge…\r\nEnjoy!\r\n// A prosaic how-to, or love letter\r\nas given here to its best by Cory Doctorow, in\r\n\r\nHomeland\r\n\r\n\r\nYou’ve had hot coffee before, and in the hands of a skilled maker, coffee can be amazing. But the fact is that coffee is one of the hardest things to get right in the world. Even with great beans and a great roast and great equipment, a little too much heat, the wrong grind, or letting things go on too long will produce a cup of bitterness. Coffee’s full of different acids, and depending on the grind, temperature, roast, and method, you can “overextract” the acids from the beans, or overheat them and oxidize them, producing that awful taste you get at donut shops and Starbucks.\r\nBut there is Another Way. If you make coffee in cold water, you only extract the sweetest acids, the highly volatile flavors that hint at chocolate and caramel, the ones that boil away or turn to sourness under imperfect circumstances. Brewing coffee in cold water sounds weird, but in fact, it’s just about the easiest way to make a cup (or a jar) of coffee.\r\nJust grind coffee – keep it coarse, with grains about the size of sea salt – and combine it with twice as much water in an airtight jar. Give it a hard shake and stick it somewhere cool overnight (I used a cooler bag loaded with ice from ice camp and wrapped the whole thing in bubble wrap for insulation). In the morning, strain it through a colander and a paper coffee filter. What you’ve got now is coffee concentrate, which you can dilute with cold water to taste – I go about half and half. If you’re feeling fancy, serve it over ice.\r\nHere’s the thing: cold-brew coffee tastes amazing, and it’s practically impossible to screw it up. Unlike espresso, where all the grounds have to be about the same size so that the high pressure water doesn’t cause fracture lines in the “puck” of coffee that leave some of the coffee unextracted and the rest overextracted, cold-brew grounds can be just about any size. Seriously, you could grind it with a stone axe. Unlike drip coffee, which goes sour and bitter if you leave the grounds in contact with the water for too long, cold-brew just gets yummier and yummier (and more and more caffeinated!) the longer the grounds sit in the water. Cold-brewing in a jar is pretty much the easiest way to make coffee in the known universe – if you don’t mind waiting overnight for the brew – and it produces the best-tasting, most potent coffee you’ve ever drunk. The only downside is that it’s kind of a pain in the ass to clean up, but if you want to spend some more money, you can invest in various gadgets to make it easier to filter the grounds, from cheap little Toddy machines all the way up to hand-blown glass “Kyoto drippers” that look like something from a mad scientist’s lab. But all you need to make a perfectly astounding cup of cold-brewed jet fuel is a mason jar, coffee, water, and something to strain it through. They’ve been making iced coffee this way in New Orleans for centuries, but for some unknown reason, it never seems to have caught on big-time.\r\n[…]\r\nIt’s funny watching someone take a sip of cold-brew for the first time, because it looks and smells strong, and it is, and coffee drinkers have been trained to think that “strong” equals “bitter.” The first mouthful washes over your tongue and the coffee flavor wafts up the back of your throat and fills up your sinus cavity and your nose is all, “THIS IS INCREDIBLY STRONG!” And the flavor is strong, but there isn’t a hint of bitterness. It’s like someone took a cup of coffee and subtracted everything that wasn’t totally delicious, and what’s left behind is a pure, powerful coffee liquor made up of all these subtle flavors: citrus and cocoa and a bit of maple syrup, all overlaid on the basic and powerful coffee taste you know and love.\r\n\r\n(CC BY-NC-ND 3.0)\r\n\r\n\r\n\r\n",
    "preview": "posts/2013-07-21-a-rough-guide-to-cold-brew/cold_brew_cats.jpg",
    "last_modified": "2022-02-15T22:38:33+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-23-marcedit-under-ubuntu-linux/",
    "title": "MarcEdit under Ubuntu Linux",
    "description": "HowTo install MarcEdit under Ubuntu 13.04, via Mono or Wine",
    "author": [
      {
        "name": "Olaf Schmalfuß",
        "url": "https://www.datamercs.net"
      }
    ],
    "date": "2013-05-23",
    "categories": [],
    "contents": "\r\noriginally posted here\r\n// MarcEdit via MONO\r\nTerry Reese’s only install instructions for Linux on his Worklog: http://blog.reeset.net/archives/805. The mentioned “Install.txt” does not even exist in the latest iteration of MarcEdit, see the relevant part below.\r\nThere is also a tutorial on Youtube: https://www.youtube.com/watch?v=N65IHRiRby8\r\nThe following set-up was done on Ubuntu 13.04\r\n\r\n# install MonoDevelop (http://monodevelop.com/)\r\nsudo apt-get install monodevelop\r\n\r\n# create you MARC records working directory\r\nmkdir MarcRecords; cd MarcRecords\r\n\r\n# download the latest version of MarcEdit from http://marcedit.reeset.net/downloads and unzip\r\nwget http://marcedit.reeset.net/software/marcedit_other.zip; unzip marcedit_other.zip; rm marcedit_other.zip\r\n\r\n# following the MarcEdit install instructions run the following command once (also check other dependencies: http://blog.reeset.net/archives/805):\r\nmono ~/MarcRecords/marcedit_linux/linux_bootloader.exe\r\n\r\n# a permanent alias makes it easier to start MarcEditin the future\r\necho \"alias marcedit='mono ~/MarcRecords/marcedit_linux/MarcEdit.exe'\" >> ~/.bash_aliases\r\n\r\n# restart Terminal in order to activate the alias\r\n\r\n# start MarcEdit.exe via alias \"marcedit\"\r\nmarcedit\r\n\r\n# or start MarcEdit.exe via\r\nmono ~/MarcRecords/marcedit_linux/MarcEdit.exe\r\n\r\nFrom Terry Reese’s “MarcEdit Installation Instructions”:\r\n\r\nInstall.txt Last Modified: 12/28/2009\r\n\r\n\"LINUX/OTHER INSTALLATION PROCEDURE:  \r\n\r\n1.1  INSTALLATION FROM ZIP  \r\n\r\na) Ensure that the dependencies have been installed  \r\n   1) Dependency list:  \r\n      i) MONO 2.4+ (Runtime plus the System.Windows.Forms library [these are sometimes separate])  \r\n     ii) YAZ 3 + YAZ 3 develop Libraries + YAZ++ ZOOM bindings  \r\n    iii) ZLIBC libraries  \r\n     iV) libxml2/libxslt libraries  \r\nb) Unzip marcedit.zip  \r\nc) Navigate to the MarcEdit program directory and run linux_bootloader.exe (example, mono linux_bootloader.exe)  \r\nd) Yaz.Sharp.dll.config — ensure that the dllmap points to the correct version of the shared libyaz object.  \r\ne) main_icon.bmp can be used for a desktop icon  \r\nf) On first run:  \r\n   a) mono MarcEdit.exe  \r\n   b) Preferences tab will open, click on other, and set the following two values:  \r\n      i) Temp path: /tmp/  \r\n     ii) MONO path: [to your full mono path; likely /usr/bin/mono]\"  \r\n// MarcEdit via WINE\r\n\r\nsudo apt-get install wine\r\n\r\nWINEPREFIX='/home/USERNAME/wine32' WINEARCH='win32' wine 'wineboot'\r\nWINEPREFIX='/home/USERNAME/wine32' bash winetricks dotnet40 corefonts\r\n\r\nwget http://marcedit.reeset.net/software/MarcEdit_Setup.msi\r\n\r\nWINEPREFIX='/home/USERNAME/wine32' msiexec /i MarcEdit_Setup.msi\r\n\r\nrm MarcEdit_Setup.msi\r\n\r\necho \"alias winmarc='WINEPREFIX='/home/USERNAME/wine32' wine /home/USERNAME/wine32/drive_c/Program\\ Files/MarcEdit\\ 5.0/MarcEdit.exe'\" >> ~/.bash_aliases\r\n\r\n# restart Terminal\r\n\r\n# start MarcEdit.exe via alias \"winmarc\"\r\nwinmarc\r\n\r\n# or start MarcEdit.exe via\r\nWINEPREFIX='/home/USERNAME/wine32' wine /home/USERNAME/wine32/drive_c/Program\\ Files/MarcEdit\\ 5.0/MarcEdit.exe\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-15T22:34:53+01:00",
    "input_file": {}
  }
]
